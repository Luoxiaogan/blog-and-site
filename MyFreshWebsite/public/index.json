[{"content":" 于是予有叹焉。古人之观于天地、山川、草木、虫鱼、鸟兽，往往有得；以其求思之深，而无不在也。夫夷以近，则遊者众；险以远，则至者少；而世之奇伟瑰怪非常之观，常在于险远，而人之所罕至焉；故非有志者，不能至也。有志矣，不随以止也，然力不足者，亦不能至也；有志与力，而又不随以怠，至于幽暗昏惑，而无物以相之，亦不能至也。然力足以至焉而不至，于人为可讥，而在己为有悔；尽吾志也，而不能至者，可以无悔矣，其孰能讥之乎？此予之所得也。\n","permalink":"http://localhost:1313/blog-and-site/posts/post3/","summary":"于是予有叹焉。古人之观于天地、山川、草木、虫鱼、鸟兽，往往有得；以其求思之深，而无不在也。夫夷以近，则遊者众；险以远，则至者少；而世之奇伟瑰怪非常之观，常在于险远，而人之所罕至焉；故非有志者，不能至也。有志矣，不随以止也，然力不足者，亦不能至也；有志与力，而又不随以怠，至于幽暗昏惑，而无物以相之，亦不能至也。然力足以至焉而不至，于人为可讥，而在己为有悔；尽吾志也，而不能至者，可以无悔矣，其孰能讥之乎？此予之所得也。","title":"Miscellaneous"},{"content":"zeroth order optimization\nsingle-point gradient estimator $G_{f}(x,\\delta,z)=\\frac{n}{\\delta}f(x+\\delta z)z$，这个estimator 的期望是某种光滑化（smoothed version）之后的期望$f^{\\delta}(x)=\\int f(x+\\delta y) , v(dy)$，$\\mathbb{E}[G_{f}(x,\\delta,z)]=\\nabla f^{\\delta}(x)$，而且是一个unbiased estimator，对于$\\nabla f$是baised\n$\\delta$ : smoothing radies orthogonally invariant distribution如何去生成，正半轴上的分布（模长分布）和单位球面的均匀分布的卷积\nthe difference between the $\\nabla f(x)$ and $\\nabla^{\\delta}f(x)$, 可以被连续性控制\n缺点：varaince 被$\\frac{1}{\\delta^2}$阶控制，而$|| \\nabla f(x)-\\nabla^{\\delta}f(x)||$被$\\delta$控制，两者不可兼得，如何解决？\na way to variance reduction: two-point gradient estimator 这样的话，variance的upper bound 的包含$\\delta$的部分是$\\delta^2$阶，是好的\n直观：当$\\delta\\to0$，就是随机的方向导数\n$$a+b=10\\\\c+d=10$$\nnon-orthogonal-invariant distributions gradient estimator 不再是某点的光滑化后的梯度了 $$V^*(s)=\\max_a d \\\\ d \\\\ s$$ $$a$$\n$$\\begin{aligned}\u0026amp;s+s=10\\\\ \u0026amp;s+v+10=10\\end{aligned}$$\n","permalink":"http://localhost:1313/blog-and-site/posts/post2/","summary":"zeroth order optimization\nsingle-point gradient estimator $G_{f}(x,\\delta,z)=\\frac{n}{\\delta}f(x+\\delta z)z$，这个estimator 的期望是某种光滑化（smoothed version）之后的期望$f^{\\delta}(x)=\\int f(x+\\delta y) , v(dy)$，$\\mathbb{E}[G_{f}(x,\\delta,z)]=\\nabla f^{\\delta}(x)$，而且是一个unbiased estimator，对于$\\nabla f$是baised\n$\\delta$ : smoothing radies orthogonally invariant distribution如何去生成，正半轴上的分布（模长分布）和单位球面的均匀分布的卷积\nthe difference between the $\\nabla f(x)$ and $\\nabla^{\\delta}f(x)$, 可以被连续性控制\n缺点：varaince 被$\\frac{1}{\\delta^2}$阶控制，而$|| \\nabla f(x)-\\nabla^{\\delta}f(x)||$被$\\delta$控制，两者不可兼得，如何解决？\na way to variance reduction: two-point gradient estimator 这样的话，variance的upper bound 的包含$\\delta$的部分是$\\delta^2$阶，是好的\n直观：当$\\delta\\to0$，就是随机的方向导数\n$$a+b=10\\\\c+d=10$$\nnon-orthogonal-invariant distributions gradient estimator 不再是某点的光滑化后的梯度了 $$V^*(s)=\\max_a d \\\\ d \\\\ s$$ $$a$$\n$$\\begin{aligned}\u0026amp;s+s=10\\\\ \u0026amp;s+v+10=10\\end{aligned}$$","title":"zeroth order optimization"},{"content":"don\u0026rsquo;t panic!!\nExamples Block math: $$\\varphi=1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots}}}$$ 好 ","permalink":"http://localhost:1313/blog-and-site/posts/post1/","summary":"don\u0026rsquo;t panic!!\nExamples Block math: $$\\varphi=1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots}}}$$ 好 ","title":"Rich Content and Shortcodes"}]